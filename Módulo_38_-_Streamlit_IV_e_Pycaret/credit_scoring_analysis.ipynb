
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto de Credit Scoring\n",
    "## Análise completa com sklearn e PyCaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyarrow pandas scikit-learn matplotlib seaborn lightgbm pycaret openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import ks_2samp\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando a base e separando safra OOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('credit_scoring.ftr')\n",
    "df['data_ref'] = pd.to_datetime(df['data_ref'])\n",
    "df = df.sort_values('data_ref')\n",
    "\n",
    "# Separando safra OOT (últimos 3 meses)\n",
    "safras = df['data_ref'].sort_values().unique()\n",
    "oot_months = safras[-3:]\n",
    "df_oot = df[df['data_ref'].isin(oot_months)].copy()\n",
    "df_dev = df[~df['data_ref'].isin(oot_months)].copy()\n",
    "\n",
    "print(f'Development shape: {df_dev.shape}')\n",
    "print(f'Out of Time shape: {df_oot.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descritiva univariada e bivariada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariada\n",
    "print(df_dev.describe(include='all'))\n",
    "\n",
    "# Bivariada\n",
    "target = 'mau'\n",
    "for col in df_dev.columns:\n",
    "    if col in ['index', 'data_ref', 'mau']: continue\n",
    "    print(f"\nAnalisando: {col}")\n",
    "    if df_dev[col].dtype == 'object':\n",
    "        print(pd.crosstab(df_dev[col], df_dev[target], normalize='index'))\n",
    "    else:\n",
    "        print(df_dev[[col, target]].groupby(target).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline com sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando variáveis\n",
    "X_dev = df_dev.drop(columns=['mau', 'index', 'data_ref'])\n",
    "y_dev = df_dev['mau']\n",
    "\n",
    "# Definindo tipos\n",
    "num_cols = X_dev.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = X_dev.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "\n",
    "# Pré-processamento\n",
    "numeric_pipeline = Pipeline([
",
    "    ('imputer', SimpleImputer(strategy='median')),
",
    "    ('scaler', StandardScaler()),
",
    "    ('pca', PCA(n_components=5))
",
    "])
",
    "
",
    "categorical_pipeline = Pipeline([
",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),
",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))
",
    "])
",
    "
",
    "preprocessor = ColumnTransformer([
",
    "    ('num', numeric_pipeline, num_cols),
",
    "    ('cat', categorical_pipeline, cat_cols)
",
    "])
",
    "
",
    "model_pipeline = Pipeline([
",
    "    ('preproc', preprocessor),
",
    "    ('model', LogisticRegression(max_iter=1000))
",
    "])
",
    "
",
    "model_pipeline.fit(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    y_proba = model.predict_proba(X)[:,1]\n",
    "    print(classification_report(y, y_pred))\n",
    "    auc = roc_auc_score(y, y_proba)\n",
    "    print(f'AUC: {auc}')\n",
    "    ks = ks_2samp(y_proba[y==1], y_proba[y==0]).statistic\n",
    "    print(f'KS: {ks}')\n",
    "    gini = 2 * auc - 1\n",
    "    print(f'Gini: {gini}')\n",
    "
",
    "print('Desenvolvimento:')\n",
    "evaluate_model(model_pipeline, X_dev, y_dev)\n",
    "print('\nOOT:')\n",
    "X_oot = df_oot.drop(columns=['mau', 'index', 'data_ref'])\n",
    "y_oot = df_oot['mau']\n",
    "evaluate_model(model_pipeline, X_oot, y_oot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyCaret com LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rodando PyCaret\n",
    "data_pycaret = df_dev.drop(columns=['index', 'data_ref'])\n",
    "clf = setup(data=data_pycaret, target='mau', session_id=123, silent=True, use_gpu=False)\n",
    "lgbm_model = create_model('lightgbm')\n",
    "tuned_model = tune_model(lgbm_model)\n",
    "evaluate_model(tuned_model)\n",
    "final_model = finalize_model(tuned_model)\n",
    "save_model(final_model, 'lightgbm_credit_scoring')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
